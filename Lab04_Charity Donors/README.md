This is a Kaggle competition, here's the context: https://www.kaggle.com/c/udacity-mlcharity-competition
- In this repo, 3 algorithms are used to train data: Random Forest, Gradient Boosting, and XGBoost. 
- Validating data using AUC (Area Under the Curve)
- Fine-tuning the best model
